{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c911e4-5bb7-43a5-b077-504e38cf8b30",
   "metadata": {},
   "source": [
    "# Advanced Tutorial 14: Ops with Custom Data Loaders\n",
    "\n",
    "## Overview\n",
    "In this tutorial, we will discuss:\n",
    "* [Using Ops with Custom Data Loaders](#ta14intro)\n",
    "    * [Op Dataset](#ta14ods)\n",
    "    * [Custom Data Loaders](#ta14cdl)\n",
    "    * [Putting Things Together](#ta14ptt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24784882-9557-41ce-8f4b-b262e10a50bf",
   "metadata": {},
   "source": [
    "<a id='ta14intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8fa379-38ef-415c-b8a9-ace65fb548c8",
   "metadata": {},
   "source": [
    "## Using Ops with Custom Data Loaders\n",
    "\n",
    "After using FE for a while you will likely become attached to the operator paradigm, but might concievably encounter a usecase which is not well supported by the default FE Pipeline. As you may already be aware, one way to avoid any limitations imposed by the FE API is to pass your own PyTorch Dataloader (or TensorFlow dataset) directly into the FE Pipeline (instead of passing a PyTorch/FE Dataset). Normally this would prevent you from using FE Ops, but there is a way around this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457c37ce-a072-44d3-9090-2442d2d880d4",
   "metadata": {},
   "source": [
    "<a id='ta14ods'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91818602-a06e-4ab2-8c76-d080a2764d5c",
   "metadata": {},
   "source": [
    "## Op Dataset\n",
    "\n",
    "FE contains an object called an OpDataset which is what we use internally to chain Ops onto datasets within our dataloader. You can construct one youself as well for use within your own dataloader. Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac1881b-74e6-4f7e-a302-52fde61d34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.dataset.data import mnist\n",
    "from fastestimator.dataset.op_dataset import OpDataset\n",
    "from fastestimator.op.numpyop.univariate import ExpandDims, Minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "759e856c-61f7-485b-a82c-8978096c6362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by getting a simple dataset\n",
    "train_data, eval_data = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "136d81ab-274a-4a7d-a2a2-68f78edbea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can manually put this dataset into an OpDataset, along with our Op list\n",
    "op_ds = OpDataset(dataset=train_data,\n",
    "                  mode=\"train\",\n",
    "                  ops=[ExpandDims(inputs=\"x\", outputs=\"x\"), \n",
    "                       Minmax(inputs=\"x\", outputs=\"x\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c9a281-7f04-4221-8e3f-1721fdbbcff5",
   "metadata": {},
   "source": [
    "Note that while this will work for most use cases, the `Batch` Op and `RemoveIf` Op will not work as expected if you try to put them into your own custom OpDataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb68930-94f1-484e-8639-6d10270e0577",
   "metadata": {},
   "source": [
    "<a id='ta14cdl'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2d84a4-9554-4d53-a00b-3ac635b88ecb",
   "metadata": {},
   "source": [
    "## Custom Data Loaders\n",
    "\n",
    "Now let's construct a custom PyTorch data loader using our OpDataset. Suppose, for example, that you want your batch size to change every step following the Fibonacci sequence. Even though the FE API lacks support for this critically important feature, you can still implement it yourself using a custom PyTorch batch sampler:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc82c6e-7bcb-49c2-ac85-56a74e4f1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb0f0dca-96a4-4af2-b872-bd1cb86ac899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A batch sampler that will increase the batch size based on the Fibonacci Sequence for a specified number of batches\n",
    "class FibonacciSampler(Sampler):\n",
    "    def __init__(self, ds_length: int, n_batches: int):\n",
    "        self.ds_ln = ds_length\n",
    "        self.n_batches = n_batches\n",
    "        self.fib_fn = lambda n: round((math.pow((1+math.sqrt(5))/2, n) - math.pow((1-math.sqrt(5))/2, n))/math.sqrt(5))\n",
    "    def __len__(self):\n",
    "        return self.ds_ln\n",
    "    def __iter__(self):\n",
    "        indices = [random.sample(range(self.ds_ln), self.fib_fn(i)) for i in range(1, self.n_batches+1)]\n",
    "        return iter(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24aaf3ed-f10a-4376-93c4-778ea2c89c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sampler = FibonacciSampler(ds_length=len(op_ds), n_batches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15f39e5d-ebd6-4074-821f-f30efff0a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's build a custom data loader using this sampler:\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83cc1e81-a51d-48a2-857f-085f2ef42c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=op_ds,\n",
    "                    batch_sampler=my_sampler,\n",
    "                    worker_init_fn=lambda _: np.random.seed(random.randint(0, 2**32 - 1)),\n",
    "                    num_workers=4)\n",
    "\n",
    "#The worker_init_fn is needed to ensure that any randomness you have in your pipeline behaves properly across different threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec62f322-0607-4868-959b-41e4d6a3ce58",
   "metadata": {},
   "source": [
    "<a id='ta14ptt'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2be0c3d-1954-4959-98c7-18eb8a31560d",
   "metadata": {},
   "source": [
    "## Putting Things Together\n",
    "\n",
    "Now that we have a custom data loader along with our op dataset, let's use them with an FE pipeline and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64d5ba25-afff-4c67-bc28-52fea6b7b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator import Pipeline\n",
    "\n",
    "pipeline = Pipeline(train_data = loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "127dda34-3e76-484f-a1d9-40fc194c652e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: torch.Size([1, 28, 28, 1])\n",
      "batch 1: torch.Size([1, 28, 28, 1])\n",
      "batch 2: torch.Size([2, 28, 28, 1])\n",
      "batch 3: torch.Size([3, 28, 28, 1])\n",
      "batch 4: torch.Size([5, 28, 28, 1])\n",
      "batch 5: torch.Size([8, 28, 28, 1])\n",
      "batch 6: torch.Size([13, 28, 28, 1])\n",
      "batch 7: torch.Size([21, 28, 28, 1])\n",
      "batch 8: torch.Size([34, 28, 28, 1])\n",
      "batch 9: torch.Size([55, 28, 28, 1])\n"
     ]
    }
   ],
   "source": [
    "data = pipeline.get_results(num_steps=10)\n",
    "for idx, batch in enumerate(data):\n",
    "    print(f\"batch {idx}: {batch['x'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca67bbe-967e-4c4b-81c1-369c4efdc0d4",
   "metadata": {},
   "source": [
    "As expected, our batch size is now increasing every step following the Fibonacci sequence, but we have also successfully integrated FE Ops into our customized pipeline. Huzzah!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
